{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681cd29e-156f-49e6-88db-f0ec341e96d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "25/04/09 19:12:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear SparkSession\n",
    "key = \"<API_KEY\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AzureDataLake\") \\\n",
    "    .config(\"spark.hadoop.fs.azure.account.auth.type.corpusdata.dfs.core.windows.net\", \"SharedKey\") \\\n",
    "    .config(\"spark.hadoop.fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.azure.account.key.corpusdata.dfs.core.windows.net\", key) \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars\", \"/app/jars/hadoop-azure-3.3.0.jar,/app/jars/hadoop-azure-datalake-3.3.0.jar,/app/jars/azure-storage-file-datalake-12.14.1.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4469c278-5ff6-43b7-bb0f-9b87434fbf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+\n",
      "|value                                                                  |\n",
      "+-----------------------------------------------------------------------+\n",
      "|                                                                       |\n",
      "|  En esta edición se han mantenido las convenciones ortográficas del   |\n",
      "|original, incluyendo las variadas normas de acentuación presentes en el|\n",
      "|                    texto. (nota del transcriptor)                     |\n",
      "|                                                                       |\n",
      "+-----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el path del contenedor en Azure Data Lake\n",
    "storage_account_name = \"corpusdata\"\n",
    "container_name = \"raw\"\n",
    "prefix = \"year=2025/language=es\"\n",
    "path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{prefix}\"\n",
    "\n",
    "# Leer los archivos desde Azure Data Lake\n",
    "df = spark.read.text(path)\n",
    "\n",
    "# Mostrar algunas filas\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f614b71-3b72-4ef4-97c9-10160a28e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 19:12:28 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1 (TID 1): Attempting to kill Python Worker\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "# Leer los archivos de texto completos con su ruta\n",
    "rdd = spark.sparkContext.wholeTextFiles(path)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df_txt = rdd.toDF([\"path\", \"content\"])\n",
    "\n",
    "# Extraer el nombre del archivo de la ruta (por ejemplo: don_quijote.txt)\n",
    "from pyspark.sql.functions import regexp_extract, input_file_name\n",
    "\n",
    "df_txt = df_txt.withColumn(\"nombre_archivo\", regexp_extract(\"path\", r\"([^/]+\\.txt)$\", 1))\n",
    "df_txt = df_txt.withColumn(\"nombre_archivo\", regexp_replace(\"nombre_archivo\", r\"_text\\.txt$\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510abc79-0823-4513-a105-46b781d0b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------------------------------------------------------------------------------------------------------+--------------+-----------------+-----------------+--------+---------+-------------------------------------------------------------+-----+\n",
      "|id     |title                                                                                                                  |author        |authoryearofbirth|authoryearofdeath|language|downloads|subjects                                                     |type |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+--------------+-----------------+-----------------+--------+---------+-------------------------------------------------------------+-----+\n",
      "|PG10228|El Presidente Díaz al Señor Edison                                                                                     |Díaz, Porfirio|1830.0           |1915.0           |['es']  |38       |{'Edison, Thomas A. (Thomas Alva), 1847-1931'}               |Sound|\n",
      "|PG10255|La Paloma                                                                                                              |NaN           |NaN              |NaN              |['es']  |176      |{'Songs -- Instrumental settings'}                           |Sound|\n",
      "|PG10261|La Bella Cubano: Habenera                                                                                              |NaN           |NaN              |NaN              |['es']  |35       |{'Habaneras', 'Violin and piano music'}                      |Sound|\n",
      "|PG10262|Que Partes El Alma: Rumba Son                                                                                          |NaN           |NaN              |NaN              |['es']  |114      |{'Folk songs, Spanish -- Cuba'}                              |Sound|\n",
      "|PG10293|Relación historica de los sucesos de la rebelión de José Gabriel Tupac-Amaru en las provincias del Peru, el año de 1780|Anonymous     |NaN              |NaN              |['es']  |105      |{'Peru -- History -- Insurrection of Tupac Amaru, 1780-1781'}|Text |\n",
      "+-------+-----------------------------------------------------------------------------------------------------------------------+--------------+-----------------+-----------------+--------+---------+-------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer CSV con pandas\n",
    "url = \"https://raw.githubusercontent.com/NelbaBarreto/programacion-ciencias-datos/refs/heads/main/data/metadata.csv\"\n",
    "df_pandas = pd.read_csv(url)\n",
    "\n",
    "# Convertir a DataFrame de Spark\n",
    "df_meta = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Filtrar solo los registros donde language sea igual a 'es'\n",
    "df_filtrado = df_meta.filter(df_meta.language == \"['es']\")\n",
    "\n",
    "df_filtrado.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc65cb8-683c-47f3-9aaa-e66244639859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 19:12:40 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 3 (TID 3): Attempting to kill Python Worker\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+\n",
      "|                path|             content|nombre_archivo|\n",
      "+--------------------+--------------------+--------------+\n",
      "|abfss://raw@corpu...|\\n[Nota del Trans...|       PG10293|\n",
      "|abfss://raw@corpu...|\\nROMANCE DE LOBO...|       PG10506|\n",
      "|abfss://raw@corpu...|\\nLegends, Tales ...|       PG10814|\n",
      "|abfss://raw@corpu...|\\nMANFREDO, DRAMA...|       PG10821|\n",
      "|abfss://raw@corpu...|\\n    EL PARAÍSO ...|       PG10822|\n",
      "|abfss://raw@corpu...|\\n[Bold text is m...|       PG10825|\n",
      "|abfss://raw@corpu...|\\n      [Ilustrac...|       PG10909|\n",
      "|abfss://raw@corpu...|\\nCredits: John H...|       PG11047|\n",
      "|abfss://raw@corpu...|\\nLA FONTANA DE O...|       PG11070|\n",
      "|abfss://raw@corpu...|\\n[Nota del Trans...|       PG11071|\n",
      "|abfss://raw@corpu...|\\n[Nota del trans...|       PG11081|\n",
      "|abfss://raw@corpu...|\\nDIARIO DE LA NA...|       PG11302|\n",
      "|abfss://raw@corpu...|\\n             LA...|       PG11529|\n",
      "|abfss://raw@corpu...|\\n     LA MONTAÑA...|       PG11598|\n",
      "|abfss://raw@corpu...|\\n     LA NIÑA DE...|       PG11657|\n",
      "|abfss://raw@corpu...|\\n     ELÍSEO REC...|       PG11663|\n",
      "|abfss://raw@corpu...|\\nMANUEL ROMERO D...|       PG11669|\n",
      "|abfss://raw@corpu...|\\nViajes por Fili...|       PG12274|\n",
      "|abfss://raw@corpu...|\\nViajes por Fili...|       PG12275|\n",
      "|abfss://raw@corpu...|\\nViajes por Fili...|       PG12276|\n",
      "+--------------------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_txt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf58061-6ed5-4ae4-8dcc-15c8081aba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = df_filtrado.withColumnRenamed(\"id\", \"nombre_archivo\")\n",
    "\n",
    "df_final = df_txt.join(df_meta, on=\"nombre_archivo\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b59f2df-fbe2-4a55-9af5-de5d26e2dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 19:12:48 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 4 (TID 4): Attempting to kill Python Worker\n",
      "25/04/09 19:12:48 WARN PythonRunner: Detected deadlock while completing task 1.0 in stage 4 (TID 5): Attempting to kill Python Worker\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------+--------------------+-----------------+-----------------+--------+---------+--------------------+----+\n",
      "|nombre_archivo|                path|             content|               title|              author|authoryearofbirth|authoryearofdeath|language|downloads|            subjects|type|\n",
      "+--------------+--------------------+--------------------+--------------------+--------------------+-----------------+-----------------+--------+---------+--------------------+----+\n",
      "|       PG11598|abfss://raw@corpu...|\\n     LA MONTAÑA...|          La Montaña|      Reclus, Elisée|           1830.0|           1905.0|  ['es']|       92|       {'Mountains'}|Text|\n",
      "|       PG10814|abfss://raw@corpu...|\\nLegends, Tales ...|                NULL|                NULL|             NULL|             NULL|    NULL|     NULL|                NULL|NULL|\n",
      "|       PG10821|abfss://raw@corpu...|\\nMANFREDO, DRAMA...|Manfredo: Drama e...|Byron, George Gor...|           1788.0|           1824.0|  ['es']|      108|           {'Drama'}|Text|\n",
      "|       PG11081|abfss://raw@corpu...|\\n[Nota del trans...|                NULL|                NULL|             NULL|             NULL|    NULL|     NULL|                NULL|NULL|\n",
      "|       PG11070|abfss://raw@corpu...|\\nLA FONTANA DE O...|   La Fontana de Oro|Pérez Galdós, Benito|           1843.0|           1920.0|  ['es']|      105|{'Historical fict...|Text|\n",
      "|       PG11657|abfss://raw@corpu...|\\n     LA NIÑA DE...|  La Niña de Luzmela|      Espina, Concha|           1869.0|           1955.0|  ['es']|       98|{'Spanish fiction...|Text|\n",
      "|       PG10293|abfss://raw@corpu...|\\n[Nota del Trans...|Relación historic...|           Anonymous|              NaN|              NaN|  ['es']|      105|{'Peru -- History...|Text|\n",
      "|       PG11529|abfss://raw@corpu...|\\n             LA...|La Espuma: Obras ...|Palacio Valdés, A...|           1853.0|           1938.0|  ['es']|       90|{'Satire', 'Madri...|Text|\n",
      "|       PG10822|abfss://raw@corpu...|\\n    EL PARAÍSO ...|El paraiso de las...|Blasco Ibáñez, Vi...|           1867.0|           1928.0|  ['es']|      158|{'Spanish fiction...|Text|\n",
      "|       PG10909|abfss://raw@corpu...|\\n      [Ilustrac...|Los Amantes de Te...|Hartzenbusch, Jua...|           1806.0|           1880.0|  ['es']|      107|{'Lovers of Terue...|Text|\n",
      "|       PG12368|abfss://raw@corpu...|\\n[Illustration: ...|                NULL|                NULL|             NULL|             NULL|    NULL|     NULL|                NULL|NULL|\n",
      "|       PG11669|abfss://raw@corpu...|\\nMANUEL ROMERO D...|La Puerta de Bron...|Romero de Terrero...|           1880.0|           1968.0|  ['es']|      120|   {'Short stories'}|Text|\n",
      "|       PG12274|abfss://raw@corpu...|\\nViajes por Fili...|Viajes por Filipi...|Alvarez Guerra, Juan|           1843.0|           1905.0|  ['es']|       94|{'Philippines -- ...|Text|\n",
      "|       PG11302|abfss://raw@corpu...|\\nDIARIO DE LA NA...|Diario de la nave...|  Villarino, Basilio|           1741.0|           1785.0|  ['es']|       96|{'Argentina -- Di...|Text|\n",
      "|       PG11663|abfss://raw@corpu...|\\n     ELÍSEO REC...|           El Arroyo|      Reclus, Elisée|           1830.0|           1905.0|  ['es']|      111|          {'Rivers'}|Text|\n",
      "|       PG12276|abfss://raw@corpu...|\\nViajes por Fili...|Viajes por Filipi...|Alvarez Guerra, Juan|           1843.0|           1905.0|  ['es']|      114|{'Philippines -- ...|Text|\n",
      "|       PG12275|abfss://raw@corpu...|\\nViajes por Fili...|Viajes por Filipi...|Alvarez Guerra, Juan|           1843.0|           1905.0|  ['es']|      108|{'Philippines -- ...|Text|\n",
      "|       PG11047|abfss://raw@corpu...|\\nCredits: John H...|                NULL|                NULL|             NULL|             NULL|    NULL|     NULL|                NULL|NULL|\n",
      "|       PG11071|abfss://raw@corpu...|\\n[Nota del Trans...|Naufragios de Alv...|Núñez Cabeza de V...|              NaN|              NaN|  ['es']|      156|{'America -- Disc...|Text|\n",
      "|       PG10825|abfss://raw@corpu...|\\n[Bold text is m...|La Navidad en las...|Altamirano, Ignac...|           1834.0|           1893.0|  ['es']|      185|{'Christmas stori...|Text|\n",
      "+--------------+--------------------+--------------------+--------------------+--------------------+-----------------+-----------------+--------+---------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ca7b6b-dd85-4d7b-8a77-e5e722bfb178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nombre_archivo',\n",
       " 'path',\n",
       " 'content',\n",
       " 'title',\n",
       " 'author',\n",
       " 'authoryearofbirth',\n",
       " 'authoryearofdeath',\n",
       " 'language',\n",
       " 'downloads',\n",
       " 'subjects',\n",
       " 'type']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c84df4-4050-4bf1-953e-0d8efacdf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop('path', 'type', 'downloads', 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295a3c52-f3b2-4885-b6a2-9d4daa1f6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import expr\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "# Tokenizar el texto\n",
    "regex_tokenizer = RegexTokenizer(\n",
    "    inputCol=\"content\",\n",
    "    outputCol=\"tokens\",\n",
    "    pattern=\"[^\\p{L}]+\",  # separa por todo lo que no sea letra (unicode)\n",
    "    minTokenLength=2,\n",
    "    gaps=True,  # pattern define lo que se usa como separador\n",
    "    toLowercase=True  # podés poner esto en lugar de transform luego\n",
    ")\n",
    "\n",
    "# Tokenizar el texto\n",
    "df_tokens = regex_tokenizer.transform(df_final)\n",
    "\n",
    "# Eliminar stopwords en español\n",
    "stopwords = StopWordsRemover.loadDefaultStopWords(\"spanish\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\", stopWords=stopwords)\n",
    "\n",
    "df_filtered = remover.transform(df_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258c9da6-37ec-4ab2-8a03-7afa82657a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 19:12:58 WARN PythonRunner: Detected deadlock while completing task 1.0 in stage 12 (TID 27): Attempting to kill Python Worker\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              tokens|\n",
      "+--------------------+\n",
      "|[la, montaña, elí...|\n",
      "|[nota, del, trans...|\n",
      "|[start, of, the, ...|\n",
      "|[legends, tales, ...|\n",
      "|[manfredo, drama,...|\n",
      "|[nota, del, trans...|\n",
      "|[la, fontana, de,...|\n",
      "|[junto, al, pasig...|\n",
      "|[la, niña, de, lu...|\n",
      "|[pío, baroja, el,...|\n",
      "|[nota, del, trans...|\n",
      "|[nota, del, trans...|\n",
      "|[nota, del, trans...|\n",
      "|[la, espuma, obra...|\n",
      "|[el, paraíso, de,...|\n",
      "|[logica, de, andr...|\n",
      "|[online, distribu...|\n",
      "|[ilustración, jua...|\n",
      "|[cuentos, de, amo...|\n",
      "|[marianela, por, ...|\n",
      "|[bailén, episodio...|\n",
      "|[dr, jose, rizal,...|\n",
      "|[illustration, pe...|\n",
      "|[esta, traducción...|\n",
      "|[apolinario, mabi...|\n",
      "|[manuel, romero, ...|\n",
      "|[viajes, por, fil...|\n",
      "|[el, gaucho, mart...|\n",
      "|[diario, de, la, ...|\n",
      "|[obras, completas...|\n",
      "|[filosofía, funda...|\n",
      "|[stan, goodman, d...|\n",
      "|[derroteros, viag...|\n",
      "|[trafalgar, benit...|\n",
      "|[elíseo, reclus, ...|\n",
      "|[expedicion, de, ...|\n",
      "|[viajes, por, fil...|\n",
      "|[viajes, por, fil...|\n",
      "|[belarmino, apolo...|\n",
      "|[credits, john, h...|\n",
      "|[jorge, ohnet, un...|\n",
      "|[nota, del, trans...|\n",
      "|[la, tierra, de, ...|\n",
      "|[en, el, fondo, d...|\n",
      "|[emilio, aguinald...|\n",
      "|[viajes, por, eur...|\n",
      "|[bold, text, is, ...|\n",
      "|[viajes, de, un, ...|\n",
      "|[juan, valera, no...|\n",
      "|[romance, de, lob...|\n",
      "+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.select(\"tokens\").show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5105c077-7e23-49cd-ab43-a99f46b06ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nombre_archivo: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- authoryearofbirth: double (nullable = true)\n",
      " |-- authoryearofdeath: double (nullable = true)\n",
      " |-- subjects: string (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered_tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4866d9a0-a8b2-4cf8-9413-676518325042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size\n",
    "\n",
    "# Agregar una nueva columna 'token_count' con la cantidad de tokens en cada fila\n",
    "df_filtered = df_filtered.withColumn('token_count', size(df_filtered['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "517cd07d-4f65-4045-a23e-8f0d60227929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Especificar la ruta local para el archivo Parquet\n",
    "ruta_local = \"libros.parquet\"\n",
    "\n",
    "# Guardar el DataFrame como un archivo Parquet en la ruta especificada, sobrescribiendo si ya existe\n",
    "df_filtered.write.mode(\"overwrite\").option(\"maxRecordsPerFile\", 1000000).parquet(ruta_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60fbde9d-c1f8-4c30-8ee9-ba0667b8a0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de tokens: 7496845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# Sumar la columna 'token_count' para obtener la cantidad total de tokens\n",
    "total_tokens = df_filtered.agg(sum('token_count')).collect()[0][0]\n",
    "\n",
    "# Mostrar el total de tokens\n",
    "print(\"Total de tokens:\", total_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
